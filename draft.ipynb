{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(pmf, epsilon=1e-4):\n",
    "    try:\n",
    "        pmf = np.array(pmf)\n",
    "        mask = pmf>epsilon\n",
    "        pmf = pmf[mask]  # 0log0 = 0\n",
    "        return -1.0 * np.dot(pmf, np.log2(pmf))\n",
    "    except TypeError as te:\n",
    "        print(pmf, \"is not iterable\")\n",
    "\n",
    "# a = np.linspace(0, 1, 100)\n",
    "# b = np.zeros(a.shape)\n",
    "# for i, e in enumerate(a):\n",
    "#     b[i] = entropy([e, 1-e])\n",
    "# fig = plt.figure()\n",
    "# plt.plot(a, b)\n",
    "# plt.show()\n",
    "\n",
    "def conditionalEntropy(cond_p, pmfs):\n",
    "    assert len(cond_p) == len(pmfs)\n",
    "    result = 0\n",
    "    for i, p in enumerate(cond_p):\n",
    "        result += p*entropy(pmfs[i, :])\n",
    "    return result\n",
    "    \n",
    "\n",
    "def empiricalEntropy(label: pd.Series):\n",
    "    pmf = label.value_counts().values / label.count()\n",
    "    return entropy(pmf)\n",
    "\n",
    "def empiricalConditionalEntropy(label: pd.Series, feature: pd.Series):\n",
    "    assert label.count() == feature.count(), \\\n",
    "        \"The length of label and feature should be the same when computing empirical conditional entropy\"\n",
    "    df = pd.DataFrame({'label':label, 'feature': feature})\n",
    "    feature_values = feature.unique()  # get all distinct feature values\n",
    "    result = 0\n",
    "    for i, value in enumerate(feature_values):\n",
    "        df_filtered = df.query('feature==@value')   # filter by feature value\n",
    "        label_filtered = df_filtered['label']\n",
    "        ee = empiricalEntropy(label_filtered)\n",
    "        cond_p = feature.value_counts()[value]/feature.count()\n",
    "        result += cond_p*ee\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36298956253708536"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./test_data.csv', delimiter=',')\n",
    "label = df['type']\n",
    "empiricalEntropy(label)\n",
    "empiricalConditionalEntropy(label=df['type'], feature=df['age'])\n",
    "empiricalEntropy(label) - empiricalConditionalEntropy(label=df['type'], feature=df['work'])\n",
    "empiricalEntropy(label) - empiricalConditionalEntropy(label=df['type'], feature=df['house'])\n",
    "empiricalEntropy(label) - empiricalConditionalEntropy(label=df['type'], feature=df['credit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '.\\data\\iris.data'\n",
    "iris_raw_data = pd.read_csv(data_path, \n",
    "        names=['sepal length', 'sepal width', 'petal length', 'petal width', 'class'], \n",
    "        delimiter=',')\n",
    "iris_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sepal length': False,\n",
       " 'sepal width': False,\n",
       " 'petal length': False,\n",
       " 'petal width': False,\n",
       " 'class': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "iris_data = iris_raw_data.copy()\n",
    "iris_data['class'], mapping_dict= iris_raw_data['class'].factorize()\n",
    "iris_data.attrs =dict(zip(iris_data.columns.values, [False, False, False, False, False]))\n",
    "iris_data.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8587587025457097\n",
      "[0.244      1.32307692 2.05833333]\n",
      "[0.83384214 0.8587587  0.74498711 0.72661841]\n"
     ]
    }
   ],
   "source": [
    "class Kmeans1d():\n",
    "    def __init__(self, epsilon=1e-2, max_step=20):\n",
    "        self.stop_epsilon = epsilon\n",
    "        self.MAX_STEP = max_step\n",
    "    \n",
    "    def fit(self, data: np.ndarray, k):\n",
    "        assert len(data.shape) == 1, \"The input data of Kmeans1d should be 1 dim\"\n",
    "        # initialization\n",
    "        low_boundary = np.min(data)\n",
    "        up_boundary = np.max(data)\n",
    "        # randomly generate k points as initial center for each class\n",
    "        center_points = low_boundary + (up_boundary-low_boundary)*np.random.rand(k)\n",
    "        center_points = np.sort(center_points)\n",
    "        center_points_last = np.ones(k)*np.inf\n",
    "        record = pd.DataFrame({'data': data, 'cluster': np.zeros(data.shape)})\n",
    "        \n",
    "        cnt = 0\n",
    "        while not self.stopping_condition(center_points, center_points_last) and cnt<self.MAX_STEP:\n",
    "            cnt = cnt + 1\n",
    "            center_points_last = center_points\n",
    "            # step1: with fixed center points, cluster the samples\n",
    "            for i, sample in enumerate(data):\n",
    "                cluster_class = np.argmin(self.squaredEuclideanDistance(center_points, sample))\n",
    "                record.iloc[i, 1] = np.int16(cluster_class)\n",
    "            \n",
    "            # step2: compute new center for each class\n",
    "            for idx, center in enumerate(center_points_last):\n",
    "                record_filtered = record.query(\"cluster==@idx\")\n",
    "                if record_filtered.empty:\n",
    "                    new_center = center\n",
    "                else:\n",
    "                    new_center = record_filtered['data'].mean()\n",
    "                center_points[idx] = new_center\n",
    "        return center_points, record\n",
    "    \n",
    "    def stopping_condition(self, points, points_last):\n",
    "        distance = self.squaredEuclideanDistance(points, points_last)\n",
    "        if np.all(distance < self.stop_epsilon):\n",
    "            return True \n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def auto_fit(self, data:np.ndarray, max_k=5, max_each=5):\n",
    "        best_k = 0\n",
    "        best_score = -np.inf\n",
    "        best_cps = None # cps: center points\n",
    "        best_rcd = None # rcd: record\n",
    "        all_score = np.zeros(max_k-1)\n",
    "        for i in np.arange(2, max_k+1):\n",
    "            best_score_for_this_k = -np.inf\n",
    "            best_rcd_for_this_k = None \n",
    "            best_cps_for_this_k = None\n",
    "            for j in np.arange(2, max_each+1):\n",
    "                # print(f\"Trying k={i} for the {j}th time\")\n",
    "                cps, rcd = self.fit(data, k=i)\n",
    "                score = self.silhouette(rcd)\n",
    "                if score > best_score_for_this_k:\n",
    "                    best_score_for_this_k = score\n",
    "                    best_rcd_for_this_k = rcd\n",
    "                    best_cps_for_this_k = cps\n",
    "            all_score[i-2] = best_score_for_this_k\n",
    "            if best_score_for_this_k > best_score:\n",
    "                best_score = best_score_for_this_k\n",
    "                best_cps = best_cps_for_this_k\n",
    "                best_rcd = best_rcd_for_this_k\n",
    "        \n",
    "        return best_score, best_cps, best_rcd, all_score\n",
    "        \n",
    "    @staticmethod\n",
    "    def squaredEuclideanDistance(x1, x2):\n",
    "        return np.square(x1-x2)\n",
    "\n",
    "    @staticmethod\n",
    "    def silhouette(data:pd.DataFrame):\n",
    "        clusters = np.sort(data['cluster'].unique())\n",
    "        a = np.zeros(data['data'].count())\n",
    "        b = np.zeros(data['data'].count())\n",
    "        s = np.zeros(data['data'].count())\n",
    "        for i, sample in enumerate(data.values):\n",
    "            num = sample[0]\n",
    "            cls = sample[1]\n",
    "            \n",
    "            # compute a(i)\n",
    "            # a measure of how well i is assigned to its cluster \n",
    "            # (the smaller the value, the better the assignment).\n",
    "            a_mask = np.int8(data['cluster'].values == cls)\n",
    "            a_mask_sum = a_mask.sum()\n",
    "            distance_to_all = Kmeans1d.squaredEuclideanDistance(num, data['data'].values)\n",
    "            if a_mask_sum == 1:\n",
    "                a[i] = 0\n",
    "            elif a_mask_sum <= 0:\n",
    "                raise ValueError(\"Cannot find sample with this class. Something wrong happened\")\n",
    "            else:\n",
    "                a[i] = np.dot(distance_to_all, a_mask) / (a_mask_sum-1)\n",
    "                \n",
    "            # compute b(i)\n",
    "            b_min = np.inf\n",
    "            for c in clusters:\n",
    "                if c == cls:\n",
    "                    continue\n",
    "                b_mask = np.int8(data['cluster'].values == c)\n",
    "                assert b_mask.sum()>0, \"Something wrong happened\"\n",
    "                temp_b = np.dot(distance_to_all, b_mask) / b_mask.sum()\n",
    "                if temp_b < b_min:\n",
    "                    b_min = temp_b\n",
    "            b[i] = b_min\n",
    "            \n",
    "            if b[i] == np.inf:\n",
    "                print(data)\n",
    "                raise ValueError(f\"WTF, b_min={b_min}\")\n",
    "            \n",
    "            # compute s(i)\n",
    "            if a_mask_sum > 1:\n",
    "                try:\n",
    "                    s[i] = 1.*(b[i]-a[i]) / np.max([a[i], b[i]])\n",
    "                except RuntimeWarning:\n",
    "                    print(f\"Something wrong happened, a={a[i]}, b={b[i]}\")\n",
    "            else:\n",
    "                s[i] = 0\n",
    "            \n",
    "        # Thus the mean s(i) over all data of the entire dataset is a measure of \n",
    "        # how appropriately the data have been clustered.\n",
    "        return np.mean(s)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_dividing_points(center_points):\n",
    "        assert type(center_points) is np.ndarray\n",
    "        cps = np.sort(center_points)\n",
    "        dividing_points = (cps[:-1] + cps[1:]) / 2.0 \n",
    "        dividing_points = np.insert(dividing_points, \n",
    "                                    [0, dividing_points.size], \n",
    "                                    [-np.inf, np.inf], \n",
    "                                    axis=0)\n",
    "        return dividing_points\n",
    "\n",
    "kk = Kmeans1d()\n",
    "# cps, rcd = kk.fit(iris_data['petal length'].values, k=5)\n",
    "best_score, best_cps, best_rcd, all_score = \\\n",
    "                kk.auto_fit(iris_data['petal width'].values, max_k=5, max_each=8)\n",
    "print(best_score)\n",
    "print(best_cps)\n",
    "print(all_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute sepal length has been discretized\n",
      "Attribute sepal width has been discretized\n",
      "Attribute petal length has been discretized\n",
      "Attribute petal width has been discretized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sepal length': array([      -inf, 5.97344815,        inf]),\n",
       " 'sepal width': array([      -inf, 2.61780428, 3.07032844, 3.55895692,        inf]),\n",
       " 'petal length': array([      -inf, 3.31110048,        inf]),\n",
       " 'petal width': array([      -inf, 0.79051852, 1.70547504,        inf])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(data:pd.DataFrame, max_k=5, max_each=8):\n",
    "    cols = data.columns.values[:-1] # except the last one\n",
    "    dividing_points_dict = {}\n",
    "    kmeans = Kmeans1d()\n",
    "    for col in cols:\n",
    "        # discrete = self.check_discrete(data, col)\n",
    "        discrete = False\n",
    "        if not discrete:\n",
    "            # apply kmeans to continuous data\n",
    "            best_score, best_cps, best_rcd, all_score = \\\n",
    "                kmeans.auto_fit(data[col].values, max_k=max_k, max_each=max_each)\n",
    "            dividing_points = kmeans.get_dividing_points(best_cps)\n",
    "            dividing_points_dict[col] = dividing_points\n",
    "            print(f\"Attribute {col} has been discretized\")\n",
    "    return dividing_points_dict\n",
    "\n",
    "dividing_points_dict = preprocess(iris_data)\n",
    "dividing_points_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,\n",
       "       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,\n",
       "       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,\n",
       "       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. , 7. , 6.4,\n",
       "       6.9, 5.5, 6.5, 5.7, 6.3, 4.9, 6.6, 5.2, 5. , 5.9, 6. , 6.1, 5.6,\n",
       "       6.7, 5.6, 5.8, 6.2, 5.6, 5.9, 6.1, 6.3, 6.1, 6.4, 6.6, 6.8, 6.7,\n",
       "       6. , 5.7, 5.5, 5.5, 5.8, 6. , 5.4, 6. , 6.7, 6.3, 5.6, 5.5, 5.5,\n",
       "       6.1, 5.8, 5. , 5.6, 5.7, 5.7, 6.2, 5.1, 5.7, 6.3, 5.8, 7.1, 6.3,\n",
       "       6.5, 7.6, 4.9, 7.3, 6.7, 7.2, 6.5, 6.4, 6.8, 5.7, 5.8, 6.4, 6.5,\n",
       "       7.7, 7.7, 6. , 6.9, 5.6, 7.7, 6.3, 6.7, 7.2, 6.2, 6.1, 6.4, 7.2,\n",
       "       7.4, 7.9, 6.4, 6.3, 6.1, 7.7, 6.3, 6.4, 6. , 6.9, 6.7, 6.9, 5.8,\n",
       "       6.8, 6.7, 6.7, 6.3, 6.5, 6.2, 5.9])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data['sepal length'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(iris_data['sepal length'].values, dividing_points_dict['sepal length'])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute sepal_length has been discretized\n",
      "Attribute sepal_width has been discretized\n",
      "Attribute petal_length has been discretized\n",
      "Attribute petal_width has been discretized\n",
      "graph LR\n",
      "root--root-->a(petal width)\n",
      "a(petal width)--petal_width<= 0.9600-->a0(Iris-setosa)\n",
      "a(petal width)--petal_width> 0.9600-->a1(sepal length)\n",
      "a1(sepal length)--sepal_length<= 5.8251-->a10(sepal width)\n",
      "a10(sepal width)--sepal_width<= 3.2179-->a100(petal length)\n",
      "a100(petal length)--petal_length<= 3.1850-->a1000(Iris-versicolor)\n",
      "a100(petal length)--petal_length> 3.1850-->a1001(Iris-versicolor)\n",
      "a1(sepal length)--sepal_length> 5.8251-->a11(sepal width)\n",
      "a11(sepal width)--sepal_width<= 3.2179-->a110(petal length)\n",
      "a110(petal length)--petal_length> 3.1850-->a1100(Iris-virginica)\n",
      "a11(sepal width)--sepal_width> 3.2179-->a111(petal length)\n",
      "a111(petal length)--petal_length> 3.1850-->a1110(Iris-virginica)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Node():\n",
    "    def __init__(self, label=None, parent=None, children=None):\n",
    "        self.parent = parent\n",
    "        self.children = children\n",
    "        self.label = label  \n",
    "        self.leaf_label = None\n",
    "        self.test_cond = None   # test condition of each internal node is here\n",
    "                                # list of str (used in pd.DataFrame.query)\n",
    "    \n",
    "    def __str__(self, level=0):\n",
    "        if not self.children:\n",
    "            ret = \"\\t\"*level + repr(self.leaf_label) + \"\\n\"\n",
    "        else:\n",
    "            ret = \"\\t\"*level + repr(self.label) + \"\\n\"\n",
    "        if self.children:\n",
    "            for child in self.children:\n",
    "                ret += child.__str__(level+1)\n",
    "        return ret\n",
    "    \n",
    "    def mermaid(self):\n",
    "        ss = self.gen_mermaid()\n",
    "        ss = 'graph LR\\nroot' + ss\n",
    "        return ss\n",
    "    \n",
    "    def gen_mermaid(self, prefix='a'):\n",
    "        if not self.children:\n",
    "            ret = \"--\" + self.label + \"-->\" + prefix + \"(\" + self.leaf_label + \")\\n\"\n",
    "        else:\n",
    "            cond = \" \".join(re.findall(\"[a-zA-Z]+\", self.test_cond[0]))\n",
    "            ret = \"--\" + self.label + \"-->\" + prefix + \"(\" + cond + \")\\n\" \n",
    "        if self.children:\n",
    "            for j, child in enumerate(self.children):\n",
    "                ret += prefix + \"(\"+cond+\")\"\n",
    "                ret += child.gen_mermaid(prefix+str(j))\n",
    "        return ret\n",
    "    \n",
    "    \n",
    "class DecisionTree():\n",
    "    def __init__(self, train_data: pd.DataFrame, \n",
    "                    mapping_dict = None,\n",
    "                    stop_threshold=1e-2):\n",
    "        self.stop_threshold = stop_threshold\n",
    "        self.mapping_dict = mapping_dict\n",
    "        # pd.DataFrame.attrs should contain whether each column is discrete or not\n",
    "        for c in train_data.columns.values:\n",
    "            if c not in train_data.attrs.keys():\n",
    "                raise ValueError(\"Input data (pd.DataFrame) should contain whether each column is discrete or not\")\n",
    "        # discretize the columns with continuous data\n",
    "        self.dividing_points_dict = self.preprocess(train_data)\n",
    "        \n",
    "        self.root = self.grow(train_data)\n",
    "        self.root.label = 'root'\n",
    "\n",
    "    def grow(self, data:pd.DataFrame):\n",
    "        if self.stopping_condition(data):\n",
    "            # finnally we reach the leaf\n",
    "            leaf = Node()\n",
    "            leaf.leaf_label = self.classify(data)\n",
    "            leaf.leaf_label = self.mapping_dict[leaf.leaf_label]\n",
    "            return leaf\n",
    "        else:\n",
    "            root = Node(label=None, children=list())\n",
    "            root.test_cond, attr = self.find_best_split(data)\n",
    "            for lb in root.test_cond:\n",
    "                assert type(lb) is str\n",
    "                sub_data = data.query(lb)\n",
    "                if sub_data.empty:\n",
    "                    continue\n",
    "                sub_data = sub_data.drop(columns=[attr])  # this attribute has been used this time\n",
    "                child = self.grow(sub_data)\n",
    "                child.parent = root\n",
    "                child.label = lb\n",
    "                root.children.append(child)\n",
    "        return root\n",
    "\n",
    "    def check_discrete(self, data: pd.DataFrame, col: str):\n",
    "        return data.attrs[col]\n",
    "\n",
    "    def stopping_condition(self, data:pd.DataFrame):\n",
    "        assert len(data.columns.values) > 0, \"Cannot find the label column\"\n",
    "        if len(data.columns.values) == 1:   # the last one column is the label of each sample\n",
    "            # all attributes have been used, thus stop\n",
    "            return True\n",
    "        if data.iloc[:,-1].nunique() == 1:\n",
    "            return True\n",
    "        max_info_gain, _, _ = self.find_largest_info_gain(data)\n",
    "        # print(max_info_gain)\n",
    "        if max_info_gain < self.stop_threshold:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def find_best_split(self, data:pd.DataFrame):\n",
    "        # select the attribute with largest information gain\n",
    "        _, attr_with_max_info_gain, attr_discrete = self.find_largest_info_gain(data)\n",
    "        if attr_discrete:\n",
    "            # for example, if available values for attr 'A' is [0, 1 ,2], then cond = ['A==0', 'A==1', 'A==2']\n",
    "            cond = [attr_with_max_info_gain+'=='+str(i) for i in data[attr_with_max_info_gain].unique()]\n",
    "        else:\n",
    "            # raise ValueError(\"Continuous data is not available now\")\n",
    "            dividing_points = self.dividing_points_dict[attr_with_max_info_gain]\n",
    "            cond = []\n",
    "            for i in range(len(dividing_points)-1):\n",
    "                if dividing_points[i] == -np.inf:\n",
    "                    ss = attr_with_max_info_gain + \"<= %.4f\"%dividing_points[i+1]\n",
    "                    cond.append(ss)\n",
    "                elif dividing_points[i+1] == np.inf:\n",
    "                    ss = attr_with_max_info_gain + \"> %.4f\"%dividing_points[i]\n",
    "                    cond.append(ss)\n",
    "                else:\n",
    "                    ss = \"%.4f < \"%dividing_points[i] +  attr_with_max_info_gain + \"<= %.4f\"%dividing_points[i+1]\n",
    "\n",
    "        return cond, attr_with_max_info_gain\n",
    "    \n",
    "    def find_largest_info_gain(self, data:pd.DataFrame):\n",
    "        \"\"\" select the attribute with largest information gain\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): data with label in the last column\n",
    "\n",
    "        Returns:\n",
    "            float: attr_with_max_info_gain, max_info_gain, attr_discrete\n",
    "        \"\"\"\n",
    "        max_info_gain = -np.inf\n",
    "        for col in data.columns.values[:-1]: # the last column is the label, thus ignore it\n",
    "            discrete = self.check_discrete(data, col)\n",
    "            if discrete:\n",
    "                info_gain = empiricalEntropy(data.iloc[:, -1]) - \\\n",
    "                            empiricalConditionalEntropy(label=data.iloc[:, -1], feature=data[col])\n",
    "            else:\n",
    "                col_feature = np.digitize(data[col].values, self.dividing_points_dict[col])-1\n",
    "                col_feature = pd.Series(col_feature)\n",
    "                info_gain = empiricalEntropy(data.iloc[:, -1]) - \\\n",
    "                            empiricalConditionalEntropy(label=data.iloc[:, -1], feature=col_feature)\n",
    "                \n",
    "            # get largest info gain\n",
    "            if info_gain > max_info_gain:\n",
    "                max_info_gain = info_gain\n",
    "                attr_with_max_info_gain = col\n",
    "                attr_discrete = discrete\n",
    "        return max_info_gain, attr_with_max_info_gain, attr_discrete\n",
    "        \n",
    "    \n",
    "    def classify(self, data:pd.DataFrame):\n",
    "        return data.iloc[:,-1].mode().values[0]\n",
    "    \n",
    "    \n",
    "    def preprocess(self, data:pd.DataFrame, max_k=5, max_each=8):\n",
    "        cols = data.columns.values[:-1] # except the last one\n",
    "        dividing_points_dict = {}\n",
    "        kmeans = Kmeans1d()\n",
    "        for col in cols:\n",
    "            discrete = self.check_discrete(data, col)\n",
    "            if not discrete:\n",
    "                # apply kmeans to continuous data\n",
    "                best_score, best_cps, best_rcd, all_score = \\\n",
    "                    kmeans.auto_fit(data[col].values, max_k=max_k, max_each=max_each)\n",
    "                dividing_points = kmeans.get_dividing_points(best_cps)\n",
    "                dividing_points_dict[col] = dividing_points\n",
    "                print(f\"Attribute {col} has been discretized\")\n",
    "        return dividing_points_dict\n",
    "            \n",
    "# # test discrete\n",
    "# dataframe = pd.read_csv('./test_data.csv', delimiter=',')\n",
    "# dataframe.attrs =dict(zip(dataframe.columns.values, [True, True, True, True, True]))\n",
    "# tree = DecisionTree(dataframe)\n",
    "# print(tree.root.mermaid())\n",
    "\n",
    "data_path = '.\\data\\iris.data'\n",
    "iris_raw_data = pd.read_csv(data_path, \n",
    "        names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'], \n",
    "        delimiter=',')\n",
    "iris_data = iris_raw_data.copy()\n",
    "iris_data['class'], mapping_dict= iris_raw_data['class'].factorize()\n",
    "iris_data.attrs =dict(zip(iris_data.columns.values, [False, False, False, False, False]))\n",
    "tree = DecisionTree(iris_data, mapping_dict)\n",
    "print(tree.root.mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'petal length'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "st = \"petal_length<= 3.2097\"\n",
    "\" \".join(re.findall(\"[a-zA-Z]+\", st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   1. sepal length in cm\n",
    "   2. sepal width in cm\n",
    "   3. petal length in cm\n",
    "   4. petal width in cm\n",
    "   5. class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x600 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(6, 5), dpi=120)\n",
    "bins = [12,10,10,10]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax = axs[i, j]\n",
    "        ax.hist(iris_data.iloc[:, i*2+j].values, bins=bins[i*2+j], linewidth=0.5, edgecolor=\"white\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.493247, 1.209247])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk.get_dividing_points(best_cps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data\n",
       "cluster      \n",
       "0.0       0.1\n",
       "1.0       1.0\n",
       "2.0       1.8"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record.groupby(['cluster']).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from âˆ’1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters.\n",
    "\n",
    "Reference: \n",
    "\n",
    "[Silhouette](https://en.wikipedia.org/wiki/Silhouette_(clustering))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24\n"
     ]
    }
   ],
   "source": [
    "a = 1.235466312\n",
    "s = \"%.2f\" % a\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('torchCPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3503c772228f865e9046df7a3dbfa9a4744f3356461e8184ac67bd899f2dd09f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
